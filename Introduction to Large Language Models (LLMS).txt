# INTRODUCTION TO LARGE LANGUAGE MODELS (LLMS)
----------------------------------------------

* Chatbots, Language Models and the Birth of AI
-----------------------------------------------
This lesson is an introduction to Large Language Models (LLMs) and text-based Generative Artificial Intelligence (AI). These technologies power many sophisticated text-based AI 
applications we see today, such as ChatGPT, released by the company OpenAI in late 2022. Before we jump into how today’s models function, we’re going to start back in 1966 to understand the history of chatbots, text generation, and the Turing test.

* The ELIZA Effect
------------------
The first digital chatbot, ELIZA, was debuted on the Massachusetts Institute of Technology (MIT) campus in 1966. It was programmed using binary code by computer scientist Joseph 
Weizenbaum. The program generated text by following a few simple rules. These rules were based on a pre-determined “script” that allowed it to assume a specific persona.

For instance, the version of ELIZA that impressed staff and students alike at MIT was known as “DOCTOR”, a kind of barebones psychotherapist who would mirror back statements typed in by 
the user of the program. So if someone typed in “I’m feeling X,” DOCTOR would respond with something like “What is making you feel X?”

ELIZA was very successful in convincing people that they were interacting with a human and not a computer! So much so that there’s even a psychological effect named after the program, the 
ELIZA effect. It refers to the tendency to unconsciously attribute “humanness” to (or anthropomorphize) computer behaviors.

* The Turing Test
-----------------
Chatbots have come a long way since the days of ELIZA. From a computer science perspective, ELIZA and ChatGPT can both be said to pass what is known as the “Turing test”.

In 1950, computer scientist Alan Turing wrote a landmark paper titled “Computing Machinery and Intelligence”, in which he investigated the question:

	What does it mean for machines to think?

He concluded that this question was fundamentally meaningless and said that the better question to ask would be:

	Can a machine successfully imitate human behavior so that it might dupe a human?

To answer this question, he devised a game. The “imitation game”, as he called it, has a human evaluator interacting with a machine and another human through a text-only channel. A 
machine is said to do well at the imitation game if the human evaluator is convinced that they were interacting with another human and not a machine. The imitation game is referred to 
today as the Turing test.

* “AI”: what is it?
-------------------
The Turing test has been a cornerstone in computer science to assess the intelligence of a machine and a lot of the detail lies in the design of the test itself. Six years after Turing’s 
paper was published, a group of scientists put together a proposal for a Summer Research Project on Artificial Intelligence (AI) at Dartmouth, often thought of historically as the moment 
that birthed the field of AI.

Instead of trying to define what AI is or is not, they sought to explain the fundamental assumption behind the pursuit of AI:

	“The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a 
	machine can be made to simulate it.”

Specifically, they were interested in how language might be useful in this pursuit :

	“An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves."

From ELIZA to ChatGPT, there is indeed a marked increase in sophistication, nuance and complexity in the abilities demonstrated by language-based technologies. What has made this possible 
was the move away from “rule-based” chatbots and towards language models that rely on neural networks to capture statistical regularities within language. Let’s dive into how these models 
work!

------------------------------------------------------------------------------------------------------------------------------------------------------------------

* Detecting Patterns in Text
----------------------------
The quest to mathematically model language dates back to more than a hundred years. In 1913, mathematician A.A. Markov analyzed letters in a Russian novel and found that there were some 
surprising patterns that could be captured by mathematics. Computer scientist and mathematician Claude Shannon followed up on this analysis a few decades later with a broad question about 
language patterns: Can we predict the next letter given a series of letters?

* Next Letter Predicton
-----------------------
For example, consider the XKCD comic shown to the right where there’s a three letter sequence “eru-”. There are only a few English language words that begin with this combination of 
letters and none of them are very common. The words “erudite”, “erupt” and the less often used “eructate” are a few possible candidates, for instance.

The context of the sentence also narrows down the possibilities for which word can occur next and still make sense.The appearance of “volcano” implies that some variation of the verb “erupt” might be an obvious choice here. The verb tense (in this case, present continuous) gives the final clue that the word “erupt” will appear in the form “erupting”.

* Natural Language Processing (NLP)
-----------------------------------
The explanation above relied on familiarity with the English language. Specifically, we relied on the patterns in language we’ve picked up from reading and speaking to inform our thinking 
as we solved this. Can we train an algorithm to do the same and possibly faster and on many sentences at once? The answer is an emphatic yes and this is the primary goal of the field of 
“Natural Language Processing” (NLP)! To automate this process using a computer, we would need to come up with a way to turn this text into math.

	Many of the initial steps in any NLP task are about standardizing things (i.e. treating language more like numbers, which lend themselves more easily to math) so that computers 
	can do text analysis.

* From Letters to Words to Tokens
---------------------------------
What is the simplest unit of language that text can be broken down to? A letter! A single letter unit is known as a “unigram”. The sentence “Oh my god, the volcano is eru-“ can be broken 
down into a series of unigrams as follows: {o, h, _, m, y, _, g, o, d, _, t, h, e, _, v, o, l, c, a, n, o, _, i, s, _, e, r, u} where the dashes (_) represent blank spaces. We could also 
break it up into two letter units, known as bigrams: where the units would look like: {oh, h_, _m, my, etc,} or three letter units, i.e. trigrams and ultimately n-letter units, known as 
n-grams.

The best choice of the length of the unit depends on the exact problem we’re trying to solve and there are many best practices to follow around this. Formalizing language this way allows 
us to build a language model on a computer to predict the next best unigram, bigram or n-gram.

Is it only letters that we can do this with? Words are a more natural unit of language and we could use them as our smallest unit. We can identify each word unit by the appearance of the 
spaces between them. The Google n-gram viewer uses words as language units to give us statistical insights into the appearance of words in Google Books.

We could also use groups of words or even subwords (like -ing, -ed, etc), often referred to as tokens in the context of language models.

The table to the right shows what this might look like for the sentence in the comic. 

* Instructions
--------------
Search the phrase “artificial intelligence” in Google Books’ n-gram viewer to view the history of the appearance of the phrase in the Google Books data base!

------------------------------------------------------------------------------------------------------------------------------------------------------------------

* Autoregressive Language Models
--------------------------------
We’ve seen in the previous exercise that the first step in any NLP task is to figure out how to turn text into numbers so we can do math with it. Before getting to the math, let’s think 
about which tasks are well suited for NLP. Some well-known language-related tasks that NLP algorithms are involved in are

	. translation (like in Google Translate)

	. completing letter sequences (autocomplete, for instance)

	. question-answer (customer service chatbots, for example)
	
	. sentiment analysis (used in content filters)

While there are many methodologies in NLP to do these tasks, the quest to build an algorithmic system that can do all of these tasks and more excites NLP researchers the most. Such a 
model is referred to as a language model. Since language is often the vehicle of human thought, the hope is that in building larger language models, an algorithmic system might exhibit a 
kind of generalized intelligence that’s worthy of comparison to humans. (This is a big and interesting question on its own.)

Language models can get large and complex but the modeling process begins with a very simple question: Given some text data to work with, how can one build an algorithm to predict the 
next best thing to say? As it turns out, a model that answers this question well is capable of doing many other language-related tasks! The text data can come in many forms, say a book, 
collection of articles, a set of websites, etc. It is often referred to as a “corpus” in NLP to indicate that it is likely gathered from many sources and digitally stored.

The word autoregressive refers to statistical models that predict future values based on past values. It is used very often in the context of language models and it means that we’re using 
previously occurring words (or word sequences) to predict the next best thing to say. The simplest way to build a language model from a text corpus is to build a giant lookup table. This 
table would contains all possible word combinations appearing in the text and their frequency of appearing so we can easily lookup how likely it is that a given sentence occurs in the 
text. Such a model is often referred to as a count-based language model.

------------------------------------------------------------------------------------------------------------------------------------------------------------------

* Count-based Autoregressive Language Models
--------------------------------------------
Let’s examine this with an example. Consider a text corpus from which we want to predict how likely it is that the sentence “What do I say next?” appears. We would build a giant lookup 
table like the one shown to the right. The questions we would try to answer would be in the following order:

	- How likely is it that the word `what` appears?
	- How likely is it that the word `do` appears after the word `what`?
	- How likely is it that the word `I` appears after the sequence `what do`?

… and so on!

The mathematical way of looking at this would be through probabilities. In the figure shown to the right, the symbol P(do | what) refers to what is known as a conditional probability:

`P(do | what)` is the probability that the word `do` appears given that the word `what` has already appeared. 

How can we calculate this? From the lookup table we see four possibilities with varying frequencies of occurrence: “what do” appears 40 times in the text; “what am”, 16 times; “what 
should”, 16 times and “what have”, 8 times. So we can estimate the probability, P (do | what) (to be read out aloud as P of “do” given “what”) thus:

, i.e., the probability that the word “what” appears to begin with, multiplied by the probability that it is followed by “do”.

Expanding this further, the probability that the sentence “What do I say next?” appears in this corpus of text would be:

Note: There are usually many more possibilities in a typical corpus but we’ve kept it short and sweet for the sake of this exercise!

* Instructions
--------------
Can you examine the counts of the next word to see if the probabilities match up? For instance, does the probability of occurrence “monkeys” after “what do” match up with the count 
tables?

You can use a similar approach as what we did in the exercise. We see four possibilities in our corpus to follow “what do” and they are “I”, “you”, “we” and “monkeys”. Examine the 
frequency occurrence of “monkeys” after “what do” and divide it by sum of counts of all 4 possibilities to get P(monkeys | what do). Based on this, what would. P(what do monkeys) be?

------------------------------------------------------------------------------------------------------------------------------------------------------------------

* Compression: Solving the Curse of Dimensionality
--------------------------------------------------

Count tables can get huge!
--------------------------
The other issue that count-based language models run into is referred to as the curse of dimensionality. This means that as the corpus of text gets bigger, so does the count table we 
would need to construct. To store and work with giant count tables requires enormous amounts of computing memory and speed. Suppose we had a document with a hundred words, and we wanted 
to calculate the probability of every five-word sentence. The number of combinations we have would be 100^5 = 10 billion counts! We can see how this problem quickly scales with the size 
of a text corpus.

Compressing Text by Approximation
---------------------------------
Neural language models help solve the curse of dimensionality by compressing the text into smaller number of parameters, often referred to as the “weights” of a model. It does so by 
trying to learn an approximation of the count table instead of the whole count table.

One way to think about this is to imagine reducing a high resolution photo to a lower resolution image. This reduced image will be easier to store and access than the higher resolution 
one and the extent to which it retains all the important features of the original image depends on the cleverness with which it is compressed! (The science fiction writer Ted Chiang 
provides a layman’s explanation of this for ChatGPT in his excellent piece in the New Yorker.)

Information Loss
----------------
If you’re wondering “Is there information loss in this process?”, the answer is yes, there is! Neural language models run the risk of sometimes assigning zero probabilities to text that 
actually exists in the corpus, thus running into the unavoidable issue of information loss. However, it is compression that allows a neural language model to generalize in a manner that 
produces novel/unseen text! This is because it allows semantic connections to be made between between (lion → predator), (predator → chasing prey) and (llama → prey) to assign a non-zero 
probability to a sentence like “A lion is chasing a llama”.

To summarize, neural language models:

	. can assign zero probabilities to existing text (compression)
	. can assign non-zero probabilities to unseen text (generalization)

In other words, compression and generalization are two sides of the same coin! We will examine this deeper in a couple of exercises but before that, let’s look into how neural networks 
are able to accomplish this feat.

------------------------------------------------------------------------------------------------------------------------------------------------------------------


































































































